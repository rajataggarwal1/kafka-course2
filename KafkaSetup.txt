Windows - Summary
In summary, for Windows
Download and Setup Java 8 JDK

Download the Kafka binaries from https://kafka.apache.org/downloads

Extract Kafka at the root of C:\

Setup Kafka bins in the Environment variables section by editing Path

Try Kafka commands using kafka-topics.bat (for example)

Edit Zookeeper & Kafka configs using NotePad++ https://notepad-plus-plus.org/download/

Create Data\zookeeper and data\kafka folder under kafka_2.12-2.0.0

zookeeper.properties: dataDir=C:/kafka_2.12-2.0.0/data/zookeeper (yes the slashes are inversed)

server.properties: log.dirs=C:/kafka_2.12-2.0.0/data/kafka (yes the slashes are inversed)

Start Zookeeper in one command line: zookeeper-server-start.bat config\zookeeper.properties

Start Kafka in another command line: kafka-server-start.bat config\server.properties



Important: For the rest of the course, don't forget to add the extension .bat to commands being run

/***************** Documentation ****************/
Configuring Producers and Consumers
Client Configurations
There exist a lot of options to:

configure producer: https://kafka.apache.org/documentation/#producerconfigs

configure consumers:  https://kafka.apache.org/documentation/#consumerconfigs

The most important options are discussed in the real-world project section, coming next



/*************************/
WINDOWS WARNING: PLEASE READ
WINDOWS USERS PLEASE READ
In the next lecture, do not run the command to DELETE topics

Because of a bug here: https://issues.apache.org/jira/browse/KAFKA-1194, it doesn't work. I'm actively working with the Kafka Dev team to see if I can get this fixed.

In the meantime, please do not delete topics. Otherwise your Kafka will crash and you won't be able to do the tutorial.

A workaround is to launch Kafka inside of a Linux VM and do the tutorial from there.

Thanks


---------------------------------------
To see the documenttaion just type the command 
Ex : kafka-console-producer

Creating kafka topics
1. Make sure to run zookeeper and kafka server before executing belwo command
--> Starting zookeeper server
->  zookeeper-server-start.bat config\zookeeper.properties

--> Starting Kafka server
-> kafka-server-start.bat config\server.properties

2. kafka-topics --zookeeper 127.0.0.1:2181 --topic first_topic --create --partitions 3 --replication-factor 1

-- we can change default setting such as partition/replication factor by going into server.properties. 

-> Show all the available topics
kafka-topics --zookeeper 127.0.0.1:2181 --list

--> Get more details about topic such as which partition it has created and what is the replication factor is?
kafka-topics --zookeeper 127.0.0.1:2181 --topic first_topic --describe
				                <Topic name>
Example below:
Topic:first_topic       PartitionCount:3        ReplicationFactor:1     Configs:
        Topic: first_topic      Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: first_topic      Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: first_topic      Partition: 2    Leader: 0       Replicas: 0     Isr: 0

--> changing default partition setting update below property
num.partitions and default.replication.factor

--> creating another topic
kafka-topics --zookeeper 127.0.0.1:2181 --topic second_topic --create --partitions 6 --replication-factor 1
			 <Local server name and 2181 id default port>
--> Deleting topics
kafka-topics --zookeeper 127.0.0.1:2181 --topic second_topic --delete
						<Topic name>	

--------- Kafka producer --------

--> running kafka producer to consume message. If everything goes well then  > will come an you start seninding message 
kafka-console-producer --broker-list 127.0.0.1:9092 --topic first_topic
            <Local machine/server : Kafka port(default 9092)>     <Topic name>

--> Providing proprty to kafka producer
kafka-console-producer --broker-list 127.0.0.1:9092 --topic first_topic --producer-property acks=all
                                                                        <Propert acks and it can have three value>  

--> what happen if we start sending message to topic does not exist: in below command new_topic does not exist
kafka-console-producer --broker-list 127.0.0.1:9092 --topic new_topic
- You will get the warning that "error fecting metadata" no lear available. But it will able to recover from error and able to produce message. Kafka serever has new topic created
(error) ([2019-08-11 23:41:39,099] WARN [Producer clientId=console-producer] Error while fetching metadata with correlation id 3 : {new_topic=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient))
- if you run the command ( kafka-topics --zookeeper 127.0.0.1:2181 --list ) then it will return all topics including new_topic

-----------kafka-consumer -----

-->  comand to run consumer -- this will only consume messgae going fowards
kafka-console-consumer --bootstrap-server 127.0.0.1:9092 --topic first_topic

- we should have producer running into another command line to consumer to consume message produce by producer

--> consume all the messgae even before consumer comes up (from begeining)
kafka-console-consumer --bootstrap-server 127.0.0.1:9092 --topic first_topic --from-beginning
                                                                           <Provide this proprty to see message from begeining>

-----------Kafka-consumer group ----------
--> command for assigning consumer to group

kafka-console-consumer --bootstrap-server 127.0.0.1:9092 --topic first_topic --group my-first-application
                                                                             <Added group property> and group name application name

let open another group using same command and start producing the message. You will see some message will go to the first consumer
and some will go to next. If we open anoter consumer then it will equally distributed. This happen becausing of partition.
Zookeeper and kafka take care themself

-- running below command after creating new group will show all message because this group has not consume all the message.but if you run same command again
then it will not show any message from begining because kafka know the this consumer group already consumed message from begining
so only new message to consume
kafka-console-consumer --bootstrap-server 127.0.0.1:9092 --topic first_topic --group my-second-application --from-begining
 

--> kafka-consumer-groups --bootstrap-server 127.0.0.1:9092 --list 
it will show all gropu including created by you and the one we started consumer without providing group

--> --describe property in any command will show details about it like partition, current_offset etc


----------------resetting offset -----------

How to replay data. because once consumed then it will start from that point. we can reset using below command
--> kafka-consumer-groups --bootstrap-server 127.0.0.1:9092 --group my-first-application --reset-offsets --to-earliest --execute --topic first_topic
                                                                                         <Reset offset from where consumer start consuming. there are mutiple propert. here we are giving to-earliest and you have to provide topic name as well>

---------------------- other CLI (command line) option
CLI Options that are good to know
The CLI have many options, but here are the other that are most commonly used:

Producer with keys

kafka-console-producer --broker-list 127.0.0.1:9092 --topic first_topic --property parse.key=true --property key.separator=,
> key,value
> another key,another value
Consumer with keys

kafka-console-consumer --bootstrap-server 127.0.0.1:9092 --topic first_topic --from-beginning --property print.key=true --property key.separator=,

********************************Kafka UI ************
There are some UI available but prefreable way of using CLI
What about UIs?
Kafka does not come bundled with a UI, but here are some recommendations
 --> Kafka Manager (for managing Kafka and instead of using CLI): https://github.com/yahoo/kafka-manager

--> Kafka Tools (will be explore in the next lecture) : www.kafkatools.com based on kafka version. It is free for personal use

You may find other UIs on the internet

Overall in this course, we perform all the actions without any UI, which is good for learning how to properly use the CLI


------------------------------------------------Kafka Cat------------------
KafkaCat as a replacement for Kafka CLI
KafkaCat (https://github.com/edenhill/kafkacat) is an open-source alternative to using the Kafka CLI, created by Magnus Edenhill.

While KafkaCat is not used in this course, if you have any interest in trying it out, I recommend reading: https://medium.com/@coderunner/debugging-with-kafkacat-df7851d21968

------------------------------


/************************  Real World Excersice *******************/
Real World Exercise
Real-World Exercise:
Before jumping to the next section for the solution, here are some pointers for some exercises:

Twitter Producer

The Twitter Producer gets data from Twitter based on some keywords and put them in a Kafka topic of your choice

Twitter Java Client: https://github.com/twitter/hbc

Twitter API Credentials: https://developer.twitter.com/

ElasticSearch Consumer

The ElasticSearch Consumer gets data from your twitter topic and inserts it into ElasticSearch

ElasticSearch Java Client: https://www.elastic.co/guide/en/elasticsearch/client/java-rest/6.4/java-rest-high.html

ElasticSearch setup:

https://www.elastic.co/guide/en/elasticsearch/reference/current/setup.html

OR https://bonsai.io/
/******************************************************************/


/*************** Connect twitter tweet with Kafka -----------------/
1. Get developer account -> create app -> there will be consumer key which will be use later
2. Go to google -> search "github twitter java" -> select hbc git hub repo (https://github.com/twitter/hbc)
3. Scroll back to dependency and find twitter dependency -> copy below code and add in kafka's application pom.xml under dependencies

------------

    <dependency>
      <groupId>com.twitter</groupId>
      <artifactId>hbc-core</artifactId> <!-- or hbc-twitter4j -->
      <version>2.2.0</version> <!-- or whatever the latest version is -->
    </dependency>
  
----------

4 create twitterProducer class and check the HBC project documentation section QuickStart
-------------------
Quickstart
Declaring the connection information:

/** Set up your blocking queues: Be sure to size these properly based on expected TPS of your stream */
BlockingQueue<String> msgQueue = new LinkedBlockingQueue<String>(100000);
-------------

// creating Topic for twitter which will be consumed by our producer
kafka-topics --zookeeper 127.0.0.1:2181 --topic twitter_tweet --create --partitions 6 --replication-factor 1

// After creating topic run consumer
kafka-console-consumer --bootstrap-server 127.0.0.1:9092 --topic twitter_tweet


